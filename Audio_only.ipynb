{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNaRuNuMYLWV"
      },
      "source": [
        "# Catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaoqcegJUOIG",
        "outputId": "e3595ea8-380d-4014-c55c-1a423f986234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-pUEIhZjUOKL"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df_all = pd.read_csv('combined_ema.csv')\n",
        "\n",
        "columns_to_drop = [\n",
        "    'stressor_partner', 'stressor_fam', 'stressor_breakdown',\n",
        "    'stressor_money', 'stressor_selfcare', 'stressor_health',\n",
        "    'stressor_otherhealth', 'stressor_household', 'stressor_child',\n",
        "    'stressor_discrimination', 'stressor_none', 'moststressful',\n",
        "    'moststressful_time', 'work_location', 'attend_fidam', 'attend_fidpm',\n",
        "    'attend_hasp', 'attend_pgy1did', 'attend_pgy2did', 'attend_pgy3did',\n",
        "    'attend_none', 'work_start', 'work_end', 'jobperformance_best',\n",
        "    'jobsatisfaction', \"jobperformance2\",\"date\",\"Sleep1BeginTimestamp\",\n",
        "    'Sleep1EndTimestamp', 'Sleep2BeginTimestamp', 'Sleep2EndTimestamp', 'Sleep3BeginTimestamp', 'Sleep3EndTimestamp'\n",
        "]\n",
        "\n",
        "df_all.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "aud = [f\"audio_{i}\" for i in range(87)]\n",
        "\n",
        "cols_to_select = ['jobperformance']\n",
        "cols_to_select.extend(aud)\n",
        "df_all = df_all.loc[:,cols_to_select]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df_all['jobperformance'] = df_all['jobperformance'].replace(' ', np.nan)\n",
        "\n",
        "df_all.dropna(subset=['jobperformance'], inplace=True)\n",
        "\n",
        "df_all['jobperformance'] = df_all['jobperformance'].astype(float)\n",
        "\n",
        "Y = df_all['jobperformance'].astype(float)  # Ensure it is numeric\n",
        "X = df_all.drop(['jobperformance'], axis=1)\n",
        "\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = X[col].astype('category')\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "for col in X_train.select_dtypes(include=['category']).columns:\n",
        "    X_train[col] = X_train[col].astype(str).fillna('missing')\n",
        "    X_val[col] = X_val[col].astype(str).fillna('missing')\n",
        "\n",
        "model = CatBoostRegressor(verbose=False)\n",
        "model.fit(\n",
        "    X_train, Y_train,\n",
        "    cat_features=[X_train.columns.get_loc(c) for c in X_train.select_dtypes(['object']).columns]  # Now it expects object type since all are converted to string\n",
        ")\n",
        "\n",
        "predictions = model.predict(X_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2SzsoGnVXAg",
        "outputId": "7d872419-b8e3-4134-d6a3-2957486fa342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data - Mean Squared Error: 0.66\n",
            "Training Data - R^2 Score: 0.48\n",
            "Validation Data - Mean Squared Error: 1.21\n",
            "Validation Data - R^2 Score: 0.15\n",
            "Training Data - CCC: 0.65\n",
            "Validation Data - CCC: 0.25\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def concordance_correlation_coefficient(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the Concordance Correlation Coefficient for two arrays.\n",
        "    \"\"\"\n",
        "    mean_true = np.mean(y_true)\n",
        "    mean_pred = np.mean(y_pred)\n",
        "\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    covariance = np.mean((y_pred - mean_pred) * (y_true - mean_true))\n",
        "\n",
        "    ccc = (2 * covariance) / (var_pred + var_true + (mean_pred - mean_true) ** 2)\n",
        "\n",
        "    return ccc\n",
        "\n",
        "\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "train_mse = mean_squared_error(Y_train, train_predictions)\n",
        "train_r2 = r2_score(Y_train, train_predictions)\n",
        "print(\"Training Data - Mean Squared Error: {:.2f}\".format(train_mse))\n",
        "print(\"Training Data - R^2 Score: {:.2f}\".format(train_r2))\n",
        "\n",
        "val_mse = mean_squared_error(Y_val, val_predictions)\n",
        "val_r2 = r2_score(Y_val, val_predictions)\n",
        "print(\"Validation Data - Mean Squared Error: {:.2f}\".format(val_mse))\n",
        "print(\"Validation Data - R^2 Score: {:.2f}\".format(val_r2))\n",
        "\n",
        "\n",
        "\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, train_predictions)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, val_predictions)\n",
        "\n",
        "print(\"Training Data - CCC: {:.2f}\".format(train_ccc))\n",
        "print(\"Validation Data - CCC: {:.2f}\".format(val_ccc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLoQxfByWiLo",
        "outputId": "d34e6021-e28e-4d08-dbb7-3041073a594a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['audio_0', 'audio_1', 'audio_2', 'audio_3', 'audio_4', 'audio_5',\n",
              "       'audio_6', 'audio_7', 'audio_8', 'audio_9', 'audio_10', 'audio_11',\n",
              "       'audio_12', 'audio_13', 'audio_14', 'audio_15', 'audio_16', 'audio_17',\n",
              "       'audio_18', 'audio_19', 'audio_20', 'audio_21', 'audio_22', 'audio_23',\n",
              "       'audio_24', 'audio_25', 'audio_26', 'audio_27', 'audio_28', 'audio_29',\n",
              "       'audio_30', 'audio_31', 'audio_32', 'audio_33', 'audio_34', 'audio_35',\n",
              "       'audio_36', 'audio_37', 'audio_38', 'audio_39', 'audio_40', 'audio_41',\n",
              "       'audio_42', 'audio_43', 'audio_44', 'audio_45', 'audio_46', 'audio_47',\n",
              "       'audio_48', 'audio_49', 'audio_50', 'audio_51', 'audio_52', 'audio_53',\n",
              "       'audio_54', 'audio_55', 'audio_56', 'audio_57', 'audio_58', 'audio_59',\n",
              "       'audio_60', 'audio_61', 'audio_62', 'audio_63', 'audio_64', 'audio_65',\n",
              "       'audio_66', 'audio_67', 'audio_68', 'audio_69', 'audio_70', 'audio_71',\n",
              "       'audio_72', 'audio_73', 'audio_74', 'audio_75', 'audio_76', 'audio_77',\n",
              "       'audio_78', 'audio_79', 'audio_80', 'audio_81', 'audio_82', 'audio_83',\n",
              "       'audio_84', 'audio_85', 'audio_86'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIdG-ch8YXx7"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9lECkt70ZmUG"
      },
      "outputs": [],
      "source": [
        "X_train_xg = X_train.copy()\n",
        "X_val_xg = X_val.copy()\n",
        "Y_train_xg = Y_train.copy()\n",
        "Y_val_xg = Y_val.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I5r1Luq8bj-A"
      },
      "outputs": [],
      "source": [
        "X_train_xg = X_train_xg.astype('category')\n",
        "X_val_xg = X_val.astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Uupqz0ocZkiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "for column in X_train_xg.columns:\n",
        "    if X_train_xg[column].dtype == 'object':\n",
        "        X_train_xg[column].fillna('missing', inplace=True)\n",
        "        X_val_xg[column].fillna('missing', inplace=True)\n",
        "\n",
        "        X_train_xg[column] = label_enc.fit_transform(X_train_xg[column])\n",
        "        X_val_xg[column] = label_enc.transform(X_val_xg[column])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iahR8V_VuTy",
        "outputId": "8d488b02-6fc2-4336-ba29-0850b4e57799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Training Data - Mean Squared Error: 0.98\n",
            "XGBoost Training Data - R² Score: 0.23\n",
            "XGBoost Validation Data - Mean Squared Error: 1.40\n",
            "XGBoost Validation Data - R² Score: 0.02\n",
            "XGBoost Training Data - CCC: 0.30\n",
            "XGBoost Validation Data - CCC: 0.04\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.6, learning_rate = 0.1,\n",
        "                             max_depth = 5, alpha = 10, n_estimators = 100,\n",
        "                                 enable_categorical=True,)\n",
        "\n",
        "xgb_model.fit(X_train_xg, Y_train_xg)\n",
        "\n",
        "xgb_train_predictions = xgb_model.predict(X_train_xg)\n",
        "\n",
        "xgb_val_predictions = xgb_model.predict(X_val_xg)\n",
        "\n",
        "xgb_train_mse = mean_squared_error(Y_train_xg, xgb_train_predictions)\n",
        "xgb_train_r2 = r2_score(Y_train_xg, xgb_train_predictions)\n",
        "\n",
        "xgb_val_mse = mean_squared_error(Y_val_xg, xgb_val_predictions)\n",
        "xgb_val_r2 = r2_score(Y_val_xg, xgb_val_predictions)\n",
        "\n",
        "print(\"XGBoost Training Data - Mean Squared Error: {:.2f}\".format(xgb_train_mse))\n",
        "print(\"XGBoost Training Data - R² Score: {:.2f}\".format(xgb_train_r2))\n",
        "print(\"XGBoost Validation Data - Mean Squared Error: {:.2f}\".format(xgb_val_mse))\n",
        "print(\"XGBoost Validation Data - R² Score: {:.2f}\".format(xgb_val_r2))\n",
        "\n",
        "def concordance_correlation_coefficient(y_true, y_pred):\n",
        "    mean_true = np.mean(y_true)\n",
        "    mean_pred = np.mean(y_pred)\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    covariance = np.mean((y_pred - mean_pred) * (y_true - mean_true))\n",
        "    ccc = (2 * covariance) / (var_pred + var_true + (mean_pred - mean_true) ** 2)\n",
        "    return ccc\n",
        "\n",
        "xgb_train_ccc = concordance_correlation_coefficient(Y_train_xg, xgb_train_predictions)\n",
        "xgb_val_ccc = concordance_correlation_coefficient(Y_val_xg, xgb_val_predictions)\n",
        "\n",
        "print(\"XGBoost Training Data - CCC: {:.2f}\".format(xgb_train_ccc))\n",
        "print(\"XGBoost Validation Data - CCC: {:.2f}\".format(xgb_val_ccc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsTz13aGchzw"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "la5tIr2Bd0cY"
      },
      "outputs": [],
      "source": [
        "Xt_backup = X_train.copy()\n",
        "Xv_backup = X_val.copy()\n",
        "Yt_backup = Y_train.copy()\n",
        "Yv_backup = Y_val.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SsVnWRvecslG"
      },
      "outputs": [],
      "source": [
        "X_train_l = X_train.copy()\n",
        "X_val_l = X_val.copy()\n",
        "Y_train_l = Y_train.copy()\n",
        "Y_val_l = Y_val.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tovw4l_GeEzC"
      },
      "outputs": [],
      "source": [
        "categorical_features = []\n",
        "for column in X_train.columns:\n",
        "    if X_train[column].dtype == 'object':\n",
        "        X_train[column] = X_train[column].astype('category')\n",
        "        X_val[column] = X_val[column].astype('category')\n",
        "        categorical_features.append(column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zde2mqleJwt",
        "outputId": "a421c352-a1bb-46cc-98d5-982881ca621e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7448\n",
            "[LightGBM] [Info] Number of data points in the train set: 542, number of used features: 87\n",
            "[LightGBM] [Info] Start training from score 2.966790\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize LightGBM\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    num_leaves=31,\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=100,\n",
        "    categorical_feature=categorical_features  # Ensure categorical features are specified\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "lgb_model.fit(\n",
        "    X_train, Y_train,\n",
        "    eval_set=[(X_val, Y_val)],\n",
        "    eval_metric='mse',\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "lgb_train_predictions = lgb_model.predict(X_train)\n",
        "lgb_val_predictions = lgb_model.predict(X_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeZAoaKMckXC",
        "outputId": "fce93ce7-2fc8-41d9-e3c9-f80c710d73e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM\n",
            "Training MSE: 0.752, R2: 0.41\n",
            "Validation MSE: 1.195, R2: 0.16\n",
            "Training CCC: 0.534\n",
            "Validation CCC: 0.256\n"
          ]
        }
      ],
      "source": [
        "# Metrics\n",
        "print(\"LightGBM\")\n",
        "train_mse = mean_squared_error(Y_train, lgb_train_predictions)\n",
        "train_r2 = r2_score(Y_train, lgb_train_predictions)\n",
        "val_mse = mean_squared_error(Y_val, lgb_val_predictions)\n",
        "val_r2 = r2_score(Y_val, lgb_val_predictions)\n",
        "\n",
        "print(\"Training MSE: {:.3f}, R2: {:.2f}\".format(train_mse, train_r2))\n",
        "print(\"Validation MSE: {:.3f}, R2: {:.2f}\".format(val_mse, val_r2))\n",
        "\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, lgb_train_predictions)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val_l, lgb_val_predictions)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J42c1Wc3fpBN"
      },
      "source": [
        "# Sk-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C8qgUxRjf6RX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "numeric_transformer = SimpleImputer(strategy='median')\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "X_train_prepared = preprocessor.fit_transform(X_train)\n",
        "X_val_prepared = preprocessor.transform(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSYC19cDemkS",
        "outputId": "5c695e37-c67d-432c-c3ce-7a51c109bf1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest - Training MSE: 0.742, R²: 0.42\n",
            "Random Forest - Validation MSE: 1.235, R²: 0.13\n",
            "Training CCC: 0.532\n",
            "Validation CCC: 0.202\n",
            "SVM - Training MSE: 1.285, R²: -0.00\n",
            "SVM - Validation MSE: 1.381, R²: 0.03\n",
            "Training CCC: 0.009\n",
            "Validation CCC: 0.038\n",
            "Linear Regression - Training MSE: 0.997, R²: 0.22\n",
            "Linear Regression - Validation MSE: 700594.983, R²: -491752.82\n",
            "Training CCC: 0.364\n",
            "Validation CCC: 0.000\n",
            "Lasso - Training MSE: 1.135, R²: 0.12\n",
            "Lasso - Validation MSE: 1.307, R²: 0.08\n",
            "Training CCC: 0.193\n",
            "Validation CCC: 0.169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.026e+02, tolerance: 6.954e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_prepared, Y_train)\n",
        "rf_train_preds = rf_model.predict(X_train_prepared)\n",
        "rf_val_preds = rf_model.predict(X_val_prepared)\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train_prepared, Y_train)\n",
        "svm_train_preds = svm_model.predict(X_train_prepared)\n",
        "svm_val_preds = svm_model.predict(X_val_prepared)\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_prepared, Y_train)\n",
        "lr_train_preds = lr_model.predict(X_train_prepared)\n",
        "lr_val_preds = lr_model.predict(X_val_prepared)\n",
        "\n",
        "# Lasso Regression\n",
        "lasso_model = Lasso(alpha=0.1)\n",
        "lasso_model.fit(X_train_prepared, Y_train)\n",
        "lasso_train_preds = lasso_model.predict(X_train_prepared)\n",
        "lasso_val_preds = lasso_model.predict(X_val_prepared)\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def evaluate_model(name, train_actuals, train_preds, val_actuals, val_preds):\n",
        "    train_mse = mean_squared_error(train_actuals, train_preds)\n",
        "    train_r2 = r2_score(train_actuals, train_preds)\n",
        "    val_mse = mean_squared_error(val_actuals, val_preds)\n",
        "    val_r2 = r2_score(val_actuals, val_preds)\n",
        "    print(f\"{name} - Training MSE: {train_mse:.3f}, R²: {train_r2:.2f}\")\n",
        "    print(f\"{name} - Validation MSE: {val_mse:.3f}, R²: {val_r2:.2f}\")\n",
        "\n",
        "evaluate_model('Random Forest', Y_train, rf_train_preds, Y_val, rf_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, rf_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, rf_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "\n",
        "evaluate_model('SVM', Y_train, svm_train_preds, Y_val, svm_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, svm_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, svm_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "evaluate_model('Linear Regression', Y_train, lr_train_preds, Y_val, lr_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, lr_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, lr_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "evaluate_model('Lasso', Y_train, lasso_train_preds, Y_val, lasso_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, lasso_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, lasso_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
