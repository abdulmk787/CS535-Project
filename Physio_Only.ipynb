{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNaRuNuMYLWV"
      },
      "source": [
        "# Catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaoqcegJUOIG",
        "outputId": "a7047a7c-49e7-4f5d-deac-a66950479226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-pUEIhZjUOKL"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df_all = pd.read_csv('combined_ema.csv')\n",
        "\n",
        "columns_to_drop = [\n",
        "    'stressor_partner', 'stressor_fam', 'stressor_breakdown',\n",
        "    'stressor_money', 'stressor_selfcare', 'stressor_health',\n",
        "    'stressor_otherhealth', 'stressor_household', 'stressor_child',\n",
        "    'stressor_discrimination', 'stressor_none', 'moststressful',\n",
        "    'moststressful_time', 'work_location', 'attend_fidam', 'attend_fidpm',\n",
        "    'attend_hasp', 'attend_pgy1did', 'attend_pgy2did', 'attend_pgy3did',\n",
        "    'attend_none', 'work_start', 'work_end', 'jobperformance_best',\n",
        "    'jobsatisfaction', \"jobperformance2\",\"date\",\"Sleep1BeginTimestamp\",\n",
        "    'Sleep1EndTimestamp', 'Sleep2BeginTimestamp', 'Sleep2EndTimestamp', 'Sleep3BeginTimestamp', 'Sleep3EndTimestamp',\n",
        "    'atypical', 'sleepquant', 'sleepqual'\n",
        "\n",
        "]\n",
        "survey = ['id','completed_ts','survey_type','activity','location','stress']\n",
        "aud = [f\"audio_{i}\" for i in range(87)]\n",
        "columns_to_drop.extend(survey)\n",
        "columns_to_drop.extend(aud)\n",
        "\n",
        "df_all.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df_all['jobperformance'] = df_all['jobperformance'].replace(' ', np.nan)\n",
        "\n",
        "df_all.dropna(subset=['jobperformance'], inplace=True)\n",
        "\n",
        "df_all['jobperformance'] = df_all['jobperformance'].astype(float)\n",
        "\n",
        "Y = df_all['jobperformance'].astype(float)  # Ensure it is numeric\n",
        "X = df_all.drop(['jobperformance'], axis=1)\n",
        "\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = X[col].astype('category')\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "for col in X_train.select_dtypes(include=['category']).columns:\n",
        "    X_train[col] = X_train[col].astype(str).fillna('missing')\n",
        "    X_val[col] = X_val[col].astype(str).fillna('missing')\n",
        "\n",
        "model = CatBoostRegressor(verbose=False)\n",
        "model.fit(\n",
        "    X_train, Y_train,\n",
        "    cat_features=[X_train.columns.get_loc(c) for c in X_train.select_dtypes(['object']).columns]  # Now it expects object type since all are converted to string\n",
        ")\n",
        "\n",
        "predictions = model.predict(X_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2SzsoGnVXAg",
        "outputId": "3f437fe8-c4b2-48a7-b06f-2192cec12851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data - Mean Squared Error: 0.35\n",
            "Training Data - R^2 Score: 0.73\n",
            "Validation Data - Mean Squared Error: 1.14\n",
            "Validation Data - R^2 Score: 0.20\n",
            "Training Data - CCC: 0.83\n",
            "Validation Data - CCC: 0.33\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def concordance_correlation_coefficient(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the Concordance Correlation Coefficient for two arrays.\n",
        "    \"\"\"\n",
        "    mean_true = np.mean(y_true)\n",
        "    mean_pred = np.mean(y_pred)\n",
        "\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    covariance = np.mean((y_pred - mean_pred) * (y_true - mean_true))\n",
        "\n",
        "    ccc = (2 * covariance) / (var_pred + var_true + (mean_pred - mean_true) ** 2)\n",
        "\n",
        "    return ccc\n",
        "\n",
        "\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "train_mse = mean_squared_error(Y_train, train_predictions)\n",
        "train_r2 = r2_score(Y_train, train_predictions)\n",
        "print(\"Training Data - Mean Squared Error: {:.2f}\".format(train_mse))\n",
        "print(\"Training Data - R^2 Score: {:.2f}\".format(train_r2))\n",
        "\n",
        "val_mse = mean_squared_error(Y_val, val_predictions)\n",
        "val_r2 = r2_score(Y_val, val_predictions)\n",
        "print(\"Validation Data - Mean Squared Error: {:.2f}\".format(val_mse))\n",
        "print(\"Validation Data - R^2 Score: {:.2f}\".format(val_r2))\n",
        "\n",
        "\n",
        "\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, train_predictions)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, val_predictions)\n",
        "\n",
        "print(\"Training Data - CCC: {:.2f}\".format(train_ccc))\n",
        "print(\"Validation Data - CCC: {:.2f}\".format(val_ccc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLoQxfByWiLo",
        "outputId": "ac6ef216-f978-416e-e57a-12c2b178deaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Cardio_caloriesOut', 'Cardio_max', 'Cardio_min', 'Cardio_minutes',\n",
              "       'Fat Burn_caloriesOut', 'Fat Burn_max', 'Fat Burn_min',\n",
              "       'Fat Burn_minutes', 'NumberSteps', 'Out of Range_caloriesOut',\n",
              "       'Out of Range_max', 'Out of Range_min', 'Out of Range_minutes',\n",
              "       'Peak_caloriesOut', 'Peak_max', 'Peak_min', 'Peak_minutes',\n",
              "       'RestingHeartRate', 'Sleep1Efficiency', 'Sleep1MinutesAwake',\n",
              "       'Sleep1MinutesStageDeep', 'Sleep1MinutesStageLight',\n",
              "       'Sleep1MinutesStageRem', 'Sleep1MinutesStageWake', 'Sleep2Efficiency',\n",
              "       'Sleep2MinutesAwake', 'Sleep2MinutesStageDeep',\n",
              "       'Sleep2MinutesStageLight', 'Sleep2MinutesStageRem',\n",
              "       'Sleep2MinutesStageWake', 'Sleep3Efficiency', 'Sleep3MinutesAwake',\n",
              "       'Sleep3MinutesStageDeep', 'Sleep3MinutesStageLight',\n",
              "       'Sleep3MinutesStageRem', 'Sleep3MinutesStageWake', 'SleepMinutesAsleep',\n",
              "       'SleepMinutesInBed', 'SleepPerDay', 'delivered_ts', 'started_ts'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIdG-ch8YXx7"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9lECkt70ZmUG"
      },
      "outputs": [],
      "source": [
        "X_train_xg = X_train.copy()\n",
        "X_val_xg = X_val.copy()\n",
        "Y_train_xg = Y_train.copy()\n",
        "Y_val_xg = Y_val.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I5r1Luq8bj-A"
      },
      "outputs": [],
      "source": [
        "X_train_xg = X_train_xg.astype('category')\n",
        "X_val_xg = X_val.astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uupqz0ocZkiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "for column in X_train_xg.columns:\n",
        "    if X_train_xg[column].dtype == 'object':\n",
        "        X_train_xg[column].fillna('missing', inplace=True)\n",
        "        X_val_xg[column].fillna('missing', inplace=True)\n",
        "\n",
        "        X_train_xg[column] = label_enc.fit_transform(X_train_xg[column])\n",
        "        X_val_xg[column] = label_enc.transform(X_val_xg[column])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iahR8V_VuTy",
        "outputId": "872b749a-e519-420f-c5fe-e5c554aec357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Training Data - Mean Squared Error: 0.75\n",
            "XGBoost Training Data - R² Score: 0.42\n",
            "XGBoost Validation Data - Mean Squared Error: 1.29\n",
            "XGBoost Validation Data - R² Score: 0.09\n",
            "XGBoost Training Data - CCC: 0.51\n",
            "XGBoost Validation Data - CCC: 0.23\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.6, learning_rate = 0.1,\n",
        "                             max_depth = 5, alpha = 10, n_estimators = 100,\n",
        "                                 enable_categorical=True,)\n",
        "\n",
        "xgb_model.fit(X_train_xg, Y_train_xg)\n",
        "\n",
        "xgb_train_predictions = xgb_model.predict(X_train_xg)\n",
        "\n",
        "xgb_val_predictions = xgb_model.predict(X_val_xg)\n",
        "\n",
        "xgb_train_mse = mean_squared_error(Y_train_xg, xgb_train_predictions)\n",
        "xgb_train_r2 = r2_score(Y_train_xg, xgb_train_predictions)\n",
        "\n",
        "xgb_val_mse = mean_squared_error(Y_val_xg, xgb_val_predictions)\n",
        "xgb_val_r2 = r2_score(Y_val_xg, xgb_val_predictions)\n",
        "\n",
        "print(\"XGBoost Training Data - Mean Squared Error: {:.2f}\".format(xgb_train_mse))\n",
        "print(\"XGBoost Training Data - R² Score: {:.2f}\".format(xgb_train_r2))\n",
        "print(\"XGBoost Validation Data - Mean Squared Error: {:.2f}\".format(xgb_val_mse))\n",
        "print(\"XGBoost Validation Data - R² Score: {:.2f}\".format(xgb_val_r2))\n",
        "\n",
        "def concordance_correlation_coefficient(y_true, y_pred):\n",
        "    mean_true = np.mean(y_true)\n",
        "    mean_pred = np.mean(y_pred)\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    covariance = np.mean((y_pred - mean_pred) * (y_true - mean_true))\n",
        "    ccc = (2 * covariance) / (var_pred + var_true + (mean_pred - mean_true) ** 2)\n",
        "    return ccc\n",
        "\n",
        "xgb_train_ccc = concordance_correlation_coefficient(Y_train_xg, xgb_train_predictions)\n",
        "xgb_val_ccc = concordance_correlation_coefficient(Y_val_xg, xgb_val_predictions)\n",
        "\n",
        "print(\"XGBoost Training Data - CCC: {:.2f}\".format(xgb_train_ccc))\n",
        "print(\"XGBoost Validation Data - CCC: {:.2f}\".format(xgb_val_ccc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsTz13aGchzw"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "la5tIr2Bd0cY"
      },
      "outputs": [],
      "source": [
        "Xt_backup = X_train.copy()\n",
        "Xv_backup = X_val.copy()\n",
        "Yt_backup = Y_train.copy()\n",
        "Yv_backup = Y_val.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SsVnWRvecslG"
      },
      "outputs": [],
      "source": [
        "X_train_l = X_train.copy()\n",
        "X_val_l = X_val.copy()\n",
        "Y_train_l = Y_train.copy()\n",
        "Y_val_l = Y_val.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tovw4l_GeEzC"
      },
      "outputs": [],
      "source": [
        "categorical_features = []\n",
        "for column in X_train.columns:\n",
        "    if X_train[column].dtype == 'object':\n",
        "        X_train[column] = X_train[column].astype('category')\n",
        "        X_val[column] = X_val[column].astype('category')\n",
        "        categorical_features.append(column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zde2mqleJwt",
        "outputId": "d8a7b0b1-aa82-4d8b-fff8-f13870121764"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] categorical_feature is set=delivered_ts,started_ts, categorical_column=39,40 will be ignored. Current value: categorical_feature=delivered_ts,started_ts\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1444\n",
            "[LightGBM] [Info] Number of data points in the train set: 542, number of used features: 29\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 2.966790\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize LightGBM\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    num_leaves=31,\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=100,\n",
        "    categorical_feature=categorical_features  # Ensure categorical features are specified\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "lgb_model.fit(\n",
        "    X_train, Y_train,\n",
        "    eval_set=[(X_val, Y_val)],\n",
        "    eval_metric='mse',\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "lgb_train_predictions = lgb_model.predict(X_train)\n",
        "lgb_val_predictions = lgb_model.predict(X_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeZAoaKMckXC",
        "outputId": "b3225129-13e1-41d0-9802-9e7c72201d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM\n",
            "Training MSE: 0.552, R2: 0.57\n",
            "Validation MSE: 1.118, R2: 0.22\n",
            "Training CCC: 0.676\n",
            "Validation CCC: 0.337\n"
          ]
        }
      ],
      "source": [
        "# Metrics\n",
        "print(\"LightGBM\")\n",
        "train_mse = mean_squared_error(Y_train, lgb_train_predictions)\n",
        "train_r2 = r2_score(Y_train, lgb_train_predictions)\n",
        "val_mse = mean_squared_error(Y_val, lgb_val_predictions)\n",
        "val_r2 = r2_score(Y_val, lgb_val_predictions)\n",
        "\n",
        "print(\"Training MSE: {:.3f}, R2: {:.2f}\".format(train_mse, train_r2))\n",
        "print(\"Validation MSE: {:.3f}, R2: {:.2f}\".format(val_mse, val_r2))\n",
        "\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, lgb_train_predictions)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val_l, lgb_val_predictions)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J42c1Wc3fpBN"
      },
      "source": [
        "# Sk-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "C8qgUxRjf6RX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "numeric_transformer = SimpleImputer(strategy='median')\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "X_train_prepared = preprocessor.fit_transform(X_train)\n",
        "X_val_prepared = preprocessor.transform(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSYC19cDemkS",
        "outputId": "1bf40b31-2234-495b-c503-35269e0c054c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest - Training MSE: 0.149, R²: 0.88\n",
            "Random Forest - Validation MSE: 1.194, R²: 0.16\n",
            "Training CCC: 0.922\n",
            "Validation CCC: 0.274\n",
            "SVM - Training MSE: 1.278, R²: 0.00\n",
            "SVM - Validation MSE: 1.426, R²: -0.00\n",
            "Training CCC: 0.009\n",
            "Validation CCC: 0.007\n",
            "Linear Regression - Training MSE: 0.062, R²: 0.95\n",
            "Linear Regression - Validation MSE: 1.966, R²: -0.38\n",
            "Training CCC: 0.975\n",
            "Validation CCC: 0.101\n",
            "Lasso - Training MSE: 1.251, R²: 0.02\n",
            "Lasso - Validation MSE: 1.458, R²: -0.02\n",
            "Training CCC: 0.043\n",
            "Validation CCC: 0.015\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_prepared, Y_train)\n",
        "rf_train_preds = rf_model.predict(X_train_prepared)\n",
        "rf_val_preds = rf_model.predict(X_val_prepared)\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train_prepared, Y_train)\n",
        "svm_train_preds = svm_model.predict(X_train_prepared)\n",
        "svm_val_preds = svm_model.predict(X_val_prepared)\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_prepared, Y_train)\n",
        "lr_train_preds = lr_model.predict(X_train_prepared)\n",
        "lr_val_preds = lr_model.predict(X_val_prepared)\n",
        "\n",
        "# Lasso Regression\n",
        "lasso_model = Lasso(alpha=0.1)\n",
        "lasso_model.fit(X_train_prepared, Y_train)\n",
        "lasso_train_preds = lasso_model.predict(X_train_prepared)\n",
        "lasso_val_preds = lasso_model.predict(X_val_prepared)\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def evaluate_model(name, train_actuals, train_preds, val_actuals, val_preds):\n",
        "    train_mse = mean_squared_error(train_actuals, train_preds)\n",
        "    train_r2 = r2_score(train_actuals, train_preds)\n",
        "    val_mse = mean_squared_error(val_actuals, val_preds)\n",
        "    val_r2 = r2_score(val_actuals, val_preds)\n",
        "    print(f\"{name} - Training MSE: {train_mse:.3f}, R²: {train_r2:.2f}\")\n",
        "    print(f\"{name} - Validation MSE: {val_mse:.3f}, R²: {val_r2:.2f}\")\n",
        "\n",
        "evaluate_model('Random Forest', Y_train, rf_train_preds, Y_val, rf_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, rf_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, rf_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "\n",
        "evaluate_model('SVM', Y_train, svm_train_preds, Y_val, svm_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, svm_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, svm_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "evaluate_model('Linear Regression', Y_train, lr_train_preds, Y_val, lr_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, lr_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, lr_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "evaluate_model('Lasso', Y_train, lasso_train_preds, Y_val, lasso_val_preds)\n",
        "train_ccc = concordance_correlation_coefficient(Y_train, lasso_train_preds)\n",
        "val_ccc = concordance_correlation_coefficient(Y_val, lasso_val_preds)\n",
        "\n",
        "print(\"Training CCC: {:.3f}\".format(train_ccc))\n",
        "print(\"Validation CCC: {:.3f}\".format(val_ccc))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
